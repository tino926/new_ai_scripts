{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tino926/new_ai_scripts/blob/main/suno_bark/bark_demo_long_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this modified from suno's sample\n"
      ],
      "metadata": {
        "id": "1yMUFaxayEJe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO47mAC5iGH7"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkizeTpG_3T7"
      },
      "outputs": [],
      "source": [
        "# install bark (make sure you have torch>=2 for much faster flash-attention)\n",
        "!pip install git+https://github.com/suno-ai/bark.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ge31CAciLNJ"
      },
      "source": [
        "## Basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9Vlr3RRt6B9"
      },
      "outputs": [],
      "source": [
        "from bark import SAMPLE_RATE, generate_audio, preload_models\n",
        "from bark.api import semantic_to_waveform\n",
        "from IPython.display import Audio\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "import nltk  # we'll use this to split into sentences\n",
        "import numpy as np\n",
        "\n",
        "from bark.generation import (\n",
        "    generate_text_semantic,\n",
        "    preload_models,\n",
        ")\n",
        "\n",
        "preload_models()\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EQuIarGgo2K-"
      },
      "outputs": [],
      "source": [
        "from scipy.io.wavfile import write as write_wav\n",
        "import nltk  # we'll use this to split into sentences\n",
        "import numpy as np\n",
        "\n",
        "# The text to be converted to voice\n",
        "script = \"\"\"\n",
        "Why did the scarecrow win an award? Because he was outstanding in his field!\n",
        "\"\"\".replace(\"\\n\", \" \").strip()\n",
        "\n",
        "# splite the text into multiple sentences (strings)\n",
        "sentences = nltk.sent_tokenize(script)\n",
        "\n",
        "# indicate the voice, v2/en_speaker_9 is a female English voice\n",
        "SPEAKER = \"v2/en_speaker_9\"\n",
        "GEN_TEMP = 0.6\n",
        "silence = np.zeros(int(0.25 * SAMPLE_RATE))  # quarter second of silence\n",
        "\n",
        "\n",
        "pieces = []\n",
        "for sentence in sentences:\n",
        "    semantic_tokens = generate_text_semantic(\n",
        "        sentence,\n",
        "        history_prompt=SPEAKER,\n",
        "        temp=GEN_TEMP,\n",
        "        min_eos_p=0.05,  # this controls how likely the generation is to end\n",
        "    )\n",
        "\n",
        "    audio_array = semantic_to_waveform(semantic_tokens, history_prompt=SPEAKER,)\n",
        "    pieces += [audio_array, silence.copy()]\n",
        "\n",
        "\n",
        "audio_array = np.concatenate(pieces)\n",
        "\n",
        "\n",
        "write_wav(\"bark_generation.wav\", SAMPLE_RATE, audio_array)\n",
        "Audio(audio_array, rate=SAMPLE_RATE*1.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_aabDFBD6yt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5FjW_dPD6o1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}