{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tino926/new_ai_scripts/blob/main/huggingface_diffusers/huggingface_diffusers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref: <https://machinelearningmastery.com/inpainting-and-outpainting-with-diffusers/>  \n",
        "ref: <https://huggingface.co/docs/diffusers/using-diffusers/inpaint>  \n",
        "ref: <https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers_doc/en/inpaint.ipynb#scrollTo=9Apdxcp_-kA3>  \n",
        "ref: <https://medium.com/@nimritakoul01/image-inpainting-using-stable-diffusion-from-hugging-face-d68a26da9fd2>  "
      ],
      "metadata": {
        "id": "Bn_pFkyhuqB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Install the 'diffusers' library for working with diffusion models\n",
        "# (e.g., Stable Diffusion)\n",
        "!pip install diffusers\n",
        "\n",
        "# Install the Segment Anything library, which is a segmentation model\n",
        "# by Facebook Research\n",
        "!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "from segment_anything import sam_model_registry, SamPredictor\n",
        "\n",
        "!pip install diffusers accelerate\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "\n",
        "!wget -q -nc https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
        "CHECKPOINT_PATH='/content/sam_vit_b_01ec64.pth'\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_TYPE = \"vit_b\""
      ],
      "metadata": {
        "id": "hgN_kY6mkvwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DEVICE)"
      ],
      "metadata": {
        "id": "8-ZcE_4O2jzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://machinelearningmastery.com/wp-content/uploads/2024/04/inpaint-example.png"
      ],
      "metadata": {
        "id": "TPCjkThzlByj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Give the path of your image\n",
        "IMAGE_PATH = '/content/inpaint-example.png'\n",
        "# Read the image from the path\n",
        "image = cv2.imread(IMAGE_PATH)\n",
        "cv2_imshow(image)\n",
        "# Convert to RGB format\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)"
      ],
      "metadata": {
        "id": "TleG8nbykzOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\n",
        "sam.to(device=DEVICE)\n",
        "mask_predictor = SamPredictor(sam)\n",
        "mask_predictor.set_image(image_rgb)\n",
        "\n",
        "# Provide points as input prompt [X, Y]-coordinates\n",
        "input_point = np.array([[250, 250]])\n",
        "input_label = np.array([1])\n",
        "\n",
        "# Predicting Segmentation mask\n",
        "masks, scores, logits = mask_predictor.predict(\n",
        "    point_coords=input_point,\n",
        "    point_labels=input_label,\n",
        "    multimask_output=False,\n",
        ")"
      ],
      "metadata": {
        "id": "KMxgjtp9lLuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = masks.astype(float) * 255\n",
        "mask = np.transpose(mask, (1, 2, 0))\n",
        "_ , bw_image = cv2.threshold(mask, 100, 255, cv2.THRESH_BINARY)\n",
        "cv2_imshow(bw_image)\n",
        "cv2.imwrite('mask.png', bw_image)\n",
        "del sam, mask_predictor   # delete models to conserve GPU memory"
      ],
      "metadata": {
        "id": "VNqZYoB5lQE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade transformers diffusers"
      ],
      "metadata": {
        "id": "SR2IhohYq9uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images using PIL\n",
        "init_image = Image.open(IMAGE_PATH)\n",
        "mask_image = Image.open('mask.png')\n",
        "\n",
        "import requests\n",
        "import PIL\n",
        "from io import BytesIO\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    return PIL.Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "\n",
        "img_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png\"\n",
        "mask_url = \"https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png\"\n",
        "\n",
        "init_image = download_image(img_url).resize((512, 512))\n",
        "mask_image = download_image(mask_url).resize((512, 512))\n",
        "\n",
        "\n",
        "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16\n",
        ")\n",
        "pipe = pipe.to(DEVICE)"
      ],
      "metadata": {
        "id": "a52xhXAulTNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"red roses in a tall vase\"\n",
        "image = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[0]\n",
        "# convert image to opencv mat\n",
        "image.save('output.png')\n",
        "\n",
        "image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "cv2_imshow(image_cv)\n"
      ],
      "metadata": {
        "id": "1Y2XgfMelrtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbGsZgjWwItV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wyd5F8BVkudx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}